name: Docs Only - Fetch CPI Documentation
 
on:
  # This allows manual triggering from the GitHub Actions tab, requiring the package_id input.
  workflow_dispatch:
    inputs:
      package_id:
        description: "The ID of the CPI Integration Package to Fetch, Document, and Commit (Summary Only)."
        required: true
        type: string

jobs:
  document:
    runs-on: ubuntu-latest
    # Using the Flashpipe container ensures the 'flashpipe' command is available.
    container:
      image: engswee/flashpipe:latest
 
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
 
      - name: ðŸŒ Flashpipe Fetch (CPI to Temporary cpi-artifacts)
        id: fetch_cpi_artifacts
        env:
          PKG_ID: ${{ github.event.inputs.package_id }}
          # Standardizing on OAuth secrets
          TMN_HOST: ${{ secrets.DEV_TMN_HOST }}
          OAUTH_HOST: ${{ secrets.DEV_OAUTH_HOST }}
          CLIENT_ID: ${{ secrets.DEV_CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.DEV_CLIENT_SECRET }}
          
        run: |
          # The directory where the artifacts will be temporarily stored for analysis
          CODE_DIR="cpi-artifacts/$PKG_ID"
          
          echo "--- Running Flashpipe to pull $PKG_ID into $CODE_DIR ---"
          
          # Pull the actual CPI package content using 'sync' targeting 'git'
          # This command pulls the data from CPI (Tenant) to the directory (Git).
          flashpipe sync \
            --package-id "$PKG_ID" \
            --dir-artifacts "$CODE_DIR" \
            --sync-package-details \
            --target "git" \
            --tmn-host "$TMN_HOST" \
            --oauth-host "$OAUTH_HOST" \
            --oauth-clientid "$CLIENT_ID" \
            --oauth-clientsecret "$CLIENT_SECRET"
          
          
          if [ ! -d "$CODE_DIR" ]; then
            echo "::error::Package directory was not created by Flashpipe. Check Package ID or CPI connection secrets."
            exit 1
          fi

      - name: ðŸ§  Analyze and Generate Consolidated Summary
        id: documentation_step
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }} 
          PKG_ID: ${{ github.event.inputs.package_id }}
        run: |
          # --- Dependency Check and Install (Revised Logic) ---
          # Checks for JQ and CURL existence and installs them if missing.
          
          # Check if either dependency is missing
          if ! command -v jq >/dev/null 2>&1 || ! command -v curl >/dev/null 2>&1; then
            echo "Missing required dependencies (JQ or CURL). Attempting installation..."
            
            # Dynamically build the list of packages needed
            PACKAGES_TO_INSTALL=""
            
            # ðŸš¨ FIX: Using standard shell concatenation (var="\$var addition") ðŸš¨
            if ! command -v jq >/dev/null 2>&1; then PACKAGES_TO_INSTALL="$PACKAGES_TO_INSTALL jq"; fi
            if ! command -v curl >/dev/null 2>&1; then PACKAGES_TO_INSTALL="$PACKAGES_TO_INSTALL curl"; fi
            
            # 1. Try APT (Debian/Ubuntu)
            if command -v apt-get >/dev/null 2>&1; then
              echo "Using apt-get to install:$PACKAGES_TO_INSTALL"
              apt-get update && apt-get install -y $PACKAGES_TO_INSTALL
              
            # 2. Try APK (Alpine Linux)
            elif command -v apk >/dev/null 2>&1; then
              echo "Using apk to install:$PACKAGES_TO_INSTALL"
              apk update && apk add $PACKAGES_TO_INSTALL
              
            # 3. Neither manager found
            else
              echo "::error::Neither 'apt-get' nor 'apk' found. Cannot install dependencies."
              exit 1
            fi
          fi
          
          # Final check after installation attempts to ensure all dependencies are available
          if ! command -v jq >/dev/null 2>&1 || ! command -v curl >/dev/null 2>&1; then
             echo "::error::Required dependencies (JQ and CURL) are still missing. Analysis step cannot proceed."
             exit 1
          fi
          # --- End Dependency Check ---

          # --- Paths ---
          CODE_DIR="cpi-artifacts/$PKG_ID"        # Source of CPI files
          DOCS_DIR="Documentation/$PKG_ID"        # Destination for the summary
          OUTPUT_FILE="$DOCS_DIR/Package_Summary.md" 
          TEMP_CONTENT_FILE="temp_content.txt" # Temporary file for collecting content
          
          # Create the required destination folder structure
          mkdir -p "$DOCS_DIR"
          
          # --- SYSTEM PROMPT (Strict 10-Point Structure) ---
          SYSTEM_PROMPT="You are a senior SAP CPI Technical Architect. Your task is to analyze ALL provided code and configuration files from a single CPI package and synthesize them into ONE consolidated Markdown documentation report. You MUST adhere strictly to the following 10-point structure: 1. High-level architecture, 2. Purpose of each iFlow, 3. Sender/Receiver systems, 4. Adapter types used, 5. Step-by-step flow explanation, 6. Mapping logic summary, 7. Groovy script explanations, 8. Error handling, 9. Security/authentication, 10. Deployment notes."

          # --- Data Consolidation (Reads from CODE_DIR) ---
          # Files to look for: Integration Flow XML, Groovy Scripts, XSLT Maps
          FILES_TO_ANALYZE=$(find "$CODE_DIR" -type f \( -name 'iFlowContent.xml' -o -name '*.groovy' -o -name '*.xslt' \) -print)

          if [ -z "$FILES_TO_ANALYZE" ]; then
              echo "::warning::No supported artifacts found in package '$PKG_ID'. Skipping documentation."
              echo "docs_generated=false" >> $GITHUB_OUTPUT
              exit 0
          fi
          
          # Use 'echo >>' redirection to safely build the content 
          for INPUT_FILE in $FILES_TO_ANALYZE; do
            echo -e "\n\n--- START ARTIFACT: $INPUT_FILE ---\n" >> "$TEMP_CONTENT_FILE"
            cat "$INPUT_FILE" >> "$TEMP_CONTENT_FILE"
            echo -e "\n--- END ARTIFACT: $INPUT_FILE ---\n" >> "$TEMP_CONTENT_FILE"
          done

          # Read the entire content from the temporary file into the variable
          FULL_ARTIFACT_CONTENT=$(cat "$TEMP_CONTENT_FILE")
          
          # Build the user query text
          USER_QUERY_TEXT="Synthesize a single, consolidated technical report following the 10 mandatory sections from the entire set of package artifacts provided below. \n\n\`\`\`text\n$FULL_ARTIFACT_CONTENT\n\`\`\`"
          
          # --- API Execution ---
          # ðŸš¨ FIX: Pass the complex USER_QUERY_TEXT to jq via a file or pipe (here using EOF marker) ðŸš¨
          # This ensures that newline characters and special characters within the content are properly
          # handled and embedded as a single, valid JSON string by jq.
          
          PAYLOAD=$(cat <<EOF | jq -n --arg system "$SYSTEM_PROMPT" --arg model "gpt-4o-mini" --slurp --raw-input '
            {
              model: $model,
              messages: [
                {role: "system", content: $system},
                # Read the entire input (which is the USER_QUERY_TEXT) and use it as the user content
                {role: "user", content: .} 
              ],
              temperature: 0.1
            }
          '
          $USER_QUERY_TEXT
          EOF
          )
          
          MAX_RETRIES=3
          RETRY_COUNT=0
          # Initialize sleep duration for exponential backoff (starting at 1 second)
          SLEEP_TIME=1 
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            API_RESPONSE=$(curl -s -X POST "https://api.openai.com/v1/chat/completions" -H "Content-Type: application/json" -H "Authorization: Bearer $OPENAI_API_KEY" -d "$PAYLOAD")
            GENERATED_TEXT=$(echo "$API_RESPONSE" | jq -r ".choices[0].message.content")

            if [ "$GENERATED_TEXT" != "null" ] && [ -n "$GENERATED_TEXT" ]; then
              echo "$GENERATED_TEXT" > "$OUTPUT_FILE"
              echo "docs_generated=true" >> $GITHUB_OUTPUT
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              # ðŸš¨ FIX: Use multiplication instead of unsupported exponentiation (**) ðŸš¨
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  echo "API call failed. Retrying in $SLEEP_TIME seconds..."
                  sleep "$SLEEP_TIME"
                  # Calculate next sleep time (1, 2, 4, 8, ...)
                  SLEEP_TIME=$((SLEEP_TIME * 2))
              fi
            fi
          done
          
          if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
            echo "docs_generated=false" >> $GITHUB_OUTPUT
          fi
          
 
      - name: ðŸ’¾ Commit Documentation Summary (Only Documentation Folder)
        if: steps.documentation_step.outputs.docs_generated == 'true'
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          
          # Add ONLY the Documentation folder to the commit index
          git add --force "Documentation"
          
          # Check if the generated documentation actually changed anything
          if git diff --cached --quiet; then
              echo "No changes detected in the documentation summary. Skipping commit."
          else
              PKG_ID="${{ github.event.inputs.package_id }}"
              git commit -m "ðŸ¤– DOCS: Generated and updated Package Summary for $PKG_ID in Documentation/ folder."
              git push
              echo "âœ… Documentation committed to repository."
          fi
         
